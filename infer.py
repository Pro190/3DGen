import torch
import os
import numpy as np
from model import Pixel2Mesh
from datasets import Pix3DDataset
import random
import argparse
from datetime import datetime
from PIL import Image
from torchvision import transforms

# ═══════════════════════════════════════════════════════════════════
# КОНФИГУРАЦИЯ (значения по умолчанию)
# ═══════════════════════════════════════════════════════════════════

DEFAULT_DATA_ROOT = './PIX3D_DATA'
DEFAULT_JSON_PATH = './PIX3D_DATA/pix3d.json'
DEFAULT_CHECKPOINT_PATH = './checkpoints/latest.pth'
DEFAULT_OUTPUT_DIR = './inference_results/'
DEFAULT_SCALE_FACTOR = 100.0
DEFAULT_NUM_SAMPLES = 10
DEFAULT_RANDOM_SEED = 42
DEFAULT_SUBDIVISIONS = 3 

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# ═══════════════════════════════════════════════════════════════════


def save_obj(filepath, vertices, faces):
    """
    Сохраняет меш в формате .OBJ
    
    Args:
        filepath: Путь для сохранения
        vertices: [V, 3] numpy array координат
        faces: [F, 3] numpy array индексов треугольников
    """
    with open(filepath, 'w') as f:
        # Заголовок
        f.write(f"# Generated by Pixel2Mesh\n")
        f.write(f"# Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"# Vertices: {len(vertices)}\n")
        f.write(f"# Faces: {len(faces)}\n\n")
        
        # Вершины (масштабируем для видимости)
        for v in vertices:
            f.write(f"v {v[0]:.6f} {v[1]:.6f} {v[2]:.6f}\n")
        
        # Грани (индексы с 1 в .OBJ формате)
        for face in faces:
            f.write(f"f {face[0]+1} {face[1]+1} {face[2]+1}\n")


def load_model(checkpoint_path, device, subdivisions=3):
    """
    Загружает обученную модель из чекпоинта
    
    Args:
        checkpoint_path: Путь к .pth файлу
        device: 'cuda' или 'cpu'
        subdivisions: Количество subdivisions (должно совпадать с обучением!)
    
    Returns:
        model: Загруженная модель в режиме eval
    """
    print(f"[infer.py] Загружаю модель с subdivisions={subdivisions} на {device}...")
    
    model = Pixel2Mesh(subdivisions=subdivisions).to(device)
    
    if not os.path.exists(checkpoint_path):
        print(f"[infer.py] ВНИМАНИЕ: Чекпоинт не найден!")
        print(f"[infer.py] Путь: {checkpoint_path}")
        print(f"[infer.py] Генерация будет использовать случайные веса (для теста пайплайна)")
        model.eval()
        return model
    
    try:
        checkpoint = torch.load(checkpoint_path, map_location=device)
        
        # Проверяем формат чекпоинта
        if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
            epoch = checkpoint.get('epoch', '?')
            print(f"[infer.py] Загружаю веса из эпохи {epoch}")
        else:
            state_dict = checkpoint
            print(f"[infer.py] Загружаю веса (старый формат)")
        
        # Очистка ключей от "module." (если модель была обернута в DataParallel)
        new_state_dict = {}
        for k, v in state_dict.items():
            new_key = k.replace('module.', '')
            new_state_dict[new_key] = v
        
        model.load_state_dict(new_state_dict, strict=False)
        print(f"[infer.py] ✓ Модель загружена успешно")
        
    except Exception as e:
        print(f"[infer.py] ОШИБКА при загрузке: {e}")
        print(f"[infer.py] Продолжаю со случайными весами")
    
    model.eval()
    return model


def process_single_image(image_path, model, output_dir, scale_factor, device):
    """
    Обработка одного изображения
    
    Args:
        image_path: Путь к изображению
        model: Обученная модель
        output_dir: Директория для сохранения
        scale_factor: Масштаб для OBJ
        device: 'cuda' или 'cpu'
    
    Returns:
        output_path: Путь к сгенерированному .obj файлу
    """
    print(f"[infer.py] Обработка изображения: {image_path}")
    
    # Подготовка трансформаций
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # Загрузка изображения
    img = Image.open(image_path).convert('RGB')
    img_tensor = transform(img).unsqueeze(0).to(device)
    
    # Inference
    with torch.no_grad():
        pred_vertices = model(img_tensor)
        pred_vertices = pred_vertices[0].cpu().numpy()
    
    # Применяем масштаб
    pred_vertices_scaled = pred_vertices * scale_factor
    
    # Сохранение
    os.makedirs(output_dir, exist_ok=True)
    base_name = os.path.splitext(os.path.basename(image_path))[0]
    filename = f'{base_name}_3d.obj'
    filepath = os.path.join(output_dir, filename)
    
    faces = model.faces
    save_obj(filepath, pred_vertices_scaled, faces)
    
    print(f"  ✓ Сохранено: {filename}")
    print(f"    Вершин: {pred_vertices.shape[0]}")
    print(f"    Граней: {len(faces)}")
    
    return filepath


def run_inference_dataset(model, dataset, num_samples, output_dir, device, scale_factor, random_seed):
    """
    Запускает inference на случайных образцах из датасета
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # Выбираем случайные индексы
    random.seed(random_seed)
    indices = random.sample(range(len(dataset)), min(num_samples, len(dataset)))
    
    # Топология сетки
    faces = model.faces
    
    print(f"\n[infer.py] Генерирую {len(indices)} моделей из датасета...")
    print("=" * 70)
    
    for idx_num, idx in enumerate(indices):
        print(f"[{idx_num+1}/{len(indices)}] Обработка образца {idx}...")
        
        # Загружаем данные
        sample = dataset[idx]
        img_tensor = sample['image'].unsqueeze(0).to(device)
        category = sample.get('category', 'unknown')
        
        # Inference
        with torch.no_grad():
            pred_vertices = model(img_tensor)
            pred_vertices = pred_vertices[0].cpu().numpy()
        
        # Применяем масштаб
        pred_vertices_scaled = pred_vertices * scale_factor
        
        # Сохраняем .OBJ
        filename = f'pred_{idx}_cat_{category}.obj'
        filepath = os.path.join(output_dir, filename)
        save_obj(filepath, pred_vertices_scaled, faces)
        
        print(f"  ✓ Сохранено: {filename}")
        print()
    
    print("=" * 70)
    print(f"[infer.py] ✓ Готово! Результаты в: {output_dir}")


def main():
    parser = argparse.ArgumentParser(description='Pixel2Mesh Inference')
    parser.add_argument('--data_root', type=str, default=DEFAULT_DATA_ROOT,
                        help='Путь к корневой директории датасета')
    parser.add_argument('--json_path', type=str, default=DEFAULT_JSON_PATH,
                        help='Путь к pix3d.json')
    parser.add_argument('--checkpoint', type=str, default=DEFAULT_CHECKPOINT_PATH,
                        help='Путь к чекпоинту модели')
    parser.add_argument('--output', type=str, default=DEFAULT_OUTPUT_DIR,
                        help='Директория для сохранения результатов')
    parser.add_argument('--image', type=str, default=None,
                        help='Путь к одному изображению (если указан, датасет игнорируется)')
    parser.add_argument('--num_samples', type=int, default=DEFAULT_NUM_SAMPLES,
                        help='Количество образцов из датасета')
    parser.add_argument('--scale', type=float, default=DEFAULT_SCALE_FACTOR,
                        help='Масштабирующий коэффициент для .OBJ')
    parser.add_argument('--subdivisions', type=int, default=DEFAULT_SUBDIVISIONS,
                        help='Количество subdivisions (должно совпадать с обучением!)')
    parser.add_argument('--seed', type=int, default=DEFAULT_RANDOM_SEED,
                        help='Random seed для воспроизводимости')
    
    args = parser.parse_args()
    
    print("=" * 70)
    print("PIXEL2MESH INFERENCE")
    print("=" * 70)
    print(f"Чекпоинт:     {args.checkpoint}")
    print(f"Выход:        {args.output}")
    print(f"Устройство:   {DEVICE}")
    print(f"Масштаб:      {args.scale}")
    print(f"Subdivisions: {args.subdivisions}")
    print("=" * 70 + "\n")
    
    # Загрузка модели
    model = load_model(args.checkpoint, DEVICE, subdivisions=args.subdivisions)
    
    # Режим работы: одно изображение или датасет
    if args.image:
        # Обработка одного изображения
        print(f"[infer.py] Режим: Одно изображение")
        if not os.path.exists(args.image):
            print(f"[infer.py] ОШИБКА: Изображение не найдено: {args.image}")
            return
        
        output_path = process_single_image(
            args.image, model, args.output, args.scale, DEVICE
        )
        print(f"\n[infer.py] ✓ Модель сохранена: {output_path}")
        
    else:
        # Обработка датасета
        print(f"[infer.py] Режим: Датасет")
        print(f"Датасет:      {args.data_root}")
        print(f"JSON:         {args.json_path}")
        print(f"Образцов:     {args.num_samples}")
        print()
        
        if not os.path.exists(args.data_root) or not os.path.exists(args.json_path):
            print(f"[infer.py] ОШИБКА: Датасет не найден!")
            return
        
        # Загрузка датасета
        print("[infer.py] Загружаю датасет...")
        dataset = Pix3DDataset(args.data_root, args.json_path)
        print(f"[infer.py] ✓ Датасет загружен: {len(dataset)} образцов\n")
        
        # Запуск inference
        run_inference_dataset(
            model, dataset, args.num_samples, args.output, 
            DEVICE, args.scale, args.seed
        )
    
    print("[infer.py] Файлы можно открыть в Blender, MeshLab или CloudCompare")


if __name__ == '__main__':
    main()