"""
================================================================================
ĞĞ²Ñ‚Ğ¾Ñ€: Ğ‘Ğ°Ğ´Ñ€Ñ…Ğ°Ğ½Ğ¾Ğ² ĞÑĞ»Ğ°Ğ½-Ğ±ĞµĞº ĞŸĞ¾Ğ»Ğ°Ğ´Ğ¾Ğ²Ğ¸Ñ‡
Ğ ÑƒĞºĞ¾Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒ: ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¼Ğ¾Ğ»Ğ¾Ñ‚Ğ¾Ğ² ĞĞ½Ğ´Ñ€ĞµĞ¹ Ğ¡ĞµÑ€Ğ³ĞµĞµĞ²Ğ¸Ñ‡
Ğ¢ĞµĞ¼Ğ° Ğ’ĞšĞ : "Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ‚Ñ€ĞµÑ…Ğ¼ĞµÑ€Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¼ĞµĞ±ĞµĞ»Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ"
ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ: ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Occupancy Network Ğ½Ğ° Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğµ PIX3D
Ğ”Ğ°Ñ‚Ğ°: 2025
================================================================================

ĞŸÑ€Ğ¾Ñ†ĞµÑÑ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Occupancy Network:

    1. Ğ—ĞĞ“Ğ Ğ£Ğ—ĞšĞ Ğ”ĞĞĞĞ«Ğ¥
       - Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¼ĞµĞ±ĞµĞ»Ğ¸ [B, 3, 224, 224]
       - 3D Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ² Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğµ [B, N, 3]
       - Ground truth occupancy [B, N] (0=ÑĞ½Ğ°Ñ€ÑƒĞ¶Ğ¸, 1=Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸)

    2. FORWARD PASS
       - Encoder: Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ â†’ Ğ»Ğ°Ñ‚ĞµĞ½Ñ‚Ğ½Ñ‹Ğ¹ Ğ²ĞµĞºÑ‚Ğ¾Ñ€ [B, 512]
       - PositionalEncoding: Ñ‚Ğ¾Ñ‡ĞºĞ¸ [B, N, 3] â†’ [B, N, 63]
       - Decoder: [latent, points_enc] â†’ logits [B, N]

    3. LOSS COMPUTATION
       - BCE Loss: Ğ±Ğ¸Ğ½Ğ°Ñ€Ğ½Ğ°Ñ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ñ‚Ğ¾Ñ‡ĞºĞ¸
       - IoU Loss: Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ IoU
       - Total = BCE + 0.5 * IoU

    4. BACKWARD PASS
       - Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²
       - Gradient clipping (Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ Ğ²Ğ·Ñ€Ñ‹Ğ²Ğ° Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²)
       - ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ²ĞµÑĞ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· AdamW

    5. Ğ’ĞĞ›Ğ˜Ğ”ĞĞ¦Ğ˜Ğ¯
       - ĞšĞ°Ğ¶Ğ´ÑƒÑ ÑĞ¿Ğ¾Ñ…Ñƒ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½Ğ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞµ
       - Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ»ÑƒÑ‡ÑˆÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ğ¾ IoU

Scheduler:
    - Warmup: Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 10 ÑĞ¿Ğ¾Ñ… LR Ñ€Ğ°ÑÑ‚Ñ‘Ñ‚ Ğ¾Ñ‚ 0.01*lr Ğ´Ğ¾ lr
    - Cosine Annealing: Ğ¿Ğ¾ÑĞ»Ğµ warmup LR ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ÑÑ Ğ¿Ğ¾ ĞºĞ¾ÑĞ¸Ğ½ÑƒÑÑƒ Ğ´Ğ¾ 1e-6

Ğ§ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹:
    - best.pth: Ğ»ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ğ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ¾Ğ¼Ñƒ IoU
    - latest.pth: Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ÑÑ ÑĞ¿Ğ¾Ñ…Ğ° (Ğ´Ğ»Ñ Ğ²Ğ¾Ğ·Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ)
    - epoch_XXX.pth: Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ

Ğ—Ğ°Ğ¿ÑƒÑĞº:
    python train.py
    
    # Ğ˜Ğ»Ğ¸ Ñ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸ĞµĞ¼ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ñ‡ĞµÑ€ĞµĞ· config:
    from config import update_config
    update_config(batch_size=64, num_epochs=300)
"""

import torch
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torch.optim import AdamW
from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR

import os
import sys
import signal
from datetime import datetime
from tqdm import tqdm
import warnings

warnings.filterwarnings('ignore')

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ Ğ¸Ğ· Ğ½Ğ°ÑˆĞ¸Ñ… Ğ¼Ğ¾Ğ´ÑƒĞ»ĞµĞ¹
from config import get_config
from model import create_model
from datasets import Pix3DDataset, collate_fn
from loss import OccupancyLoss


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GRACEFUL SHUTDOWN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#
# ĞŸÑ€Ğ¸ Ğ½Ğ°Ğ¶Ğ°Ñ‚Ğ¸Ğ¸ Ctrl+C Ğ¸Ğ»Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ SIGTERM:
#   1. Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ÑÑ Ñ„Ğ»Ğ°Ğ³ STOP_TRAINING
#   2. Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ ÑĞ¿Ğ¾Ñ…Ğ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ°ĞµÑ‚ÑÑ
#   3. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ÑÑ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚
#   4. ĞŸÑ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ° ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞ°ĞµÑ‚ÑÑ
#
# Ğ­Ñ‚Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¿Ğ¾Ñ‚ĞµÑ€Ñ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞµ.
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

STOP_TRAINING = False


def signal_handler(signum, frame):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ graceful shutdown."""
    global STOP_TRAINING
    print("\n" + "=" * 60)
    print("[train.py] ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½ ÑĞ¸Ğ³Ğ½Ğ°Ğ» Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ (Ctrl+C Ğ¸Ğ»Ğ¸ SIGTERM)")
    print("[train.py] Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞ°Ñ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ ÑĞ¿Ğ¾Ñ…Ñƒ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚...")
    print("=" * 60)
    STOP_TRAINING = True


# Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸
signal.signal(signal.SIGINT, signal_handler)   # Ctrl+C
signal.signal(signal.SIGTERM, signal_handler)  # kill


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞšĞ›ĞĞ¡Ğ¡ TRAINER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Trainer:
    """
    ĞšĞ»Ğ°ÑÑ Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Occupancy Network.
    
    Ğ˜Ğ½ĞºĞ°Ğ¿ÑÑƒĞ»Ğ¸Ñ€ÑƒĞµÑ‚:
        - ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¸ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€
        - Ğ¦Ğ¸ĞºĞ» Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸
        - Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ/Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºÑƒ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ¾Ğ²
        - Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
    
    Args:
        cfg: ĞĞ±ÑŠĞµĞºÑ‚ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸ (Ğ¸Ğ· config.py)
    
    ĞŸÑ€Ğ¸Ğ¼ĞµÑ€:
        cfg = get_config()
        trainer = Trainer(cfg)
        trainer.train(train_loader, val_loader)
    """
    
    def __init__(self, cfg):
        self.cfg = cfg
        self.device = cfg.device
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ¾ ÑĞ¸ÑÑ‚ĞµĞ¼Ğµ
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        print(f"[train.py] Device: {self.device}")
        
        if self.device == 'cuda':
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
            print(f"[train.py] GPU: {gpu_name} ({gpu_memory:.1f} GB)")
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        #
        # create_model() Ğ¸Ğ· model.py ÑĞ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ OccupancyNetwork:
        #   - Encoder: ResNet50 â†’ 512-dim latent
        #   - PositionalEncoding: 3D coords â†’ 63-dim
        #   - Decoder: MLP (512+63) â†’ 1
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        self.model = create_model(
            latent_dim=cfg.model.latent_dim,
            num_frequencies=cfg.model.num_frequencies
        ).to(self.device)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Loss Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        #
        # OccupancyLoss = BCE + 0.5 * IoU
        # BCE: ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¹ loss Ğ´Ğ»Ñ Ğ±Ğ¸Ğ½Ğ°Ñ€Ğ½Ğ¾Ğ¹ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸
        # IoU: Ğ´Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºÑƒ IoU
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        self.criterion = OccupancyLoss(
            bce_weight=1.0,
            iou_weight=0.5
        )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ° AdamW
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        #
        # AdamW = Adam + Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ğ¹ Weight Decay
        # Weight Decay (L2 Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ) Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚ Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ¿ĞµÑ€ĞµĞ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        self.optimizer = AdamW(
            self.model.parameters(),
            lr=cfg.train.learning_rate,
            weight_decay=cfg.train.weight_decay,
            betas=(0.9, 0.999)  # Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Adam
        )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Learning Rate Scheduler
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        #
        # Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ "Warmup + Cosine Annealing":
        #
        #   LR
        #   ^
        #   |     /â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾â€¾\
        #   |    /             \
        #   |   /               \
        #   |  /                 \
        #   | /                   \____
        #   |/                         
        #   +-------------------------> Epoch
        #     |        |              |
        #   Warmup   Peak          End
        #
        # 1. Warmup (Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 10 ÑĞ¿Ğ¾Ñ…): LR Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ¾ Ñ€Ğ°ÑÑ‚Ñ‘Ñ‚ Ğ¾Ñ‚ 0.01*lr Ğ´Ğ¾ lr
        #    Ğ­Ñ‚Ğ¾ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ (Ğ²ĞµÑĞ° ĞµÑ‰Ñ‘ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğµ)
        #
        # 2. Cosine Annealing (Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ¿Ğ¾Ñ…Ğ¸): LR ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ÑÑ Ğ¿Ğ¾ ĞºĞ¾ÑĞ¸Ğ½ÑƒÑÑƒ
        #    ĞŸĞ»Ğ°Ğ²Ğ½Ğ¾Ğµ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚ "Ğ´Ğ¾ÑˆĞ»Ğ¸Ñ„Ğ¾Ğ²Ğ°Ñ‚ÑŒ" Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        # Warmup scheduler: 0.01*lr â†’ lr Ğ·Ğ° warmup_epochs ÑĞ¿Ğ¾Ñ…
        warmup_scheduler = LinearLR(
            self.optimizer,
            start_factor=0.01,  # ĞĞ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ñ 1% Ğ¾Ñ‚ lr
            end_factor=1.0,      # Ğ—Ğ°ĞºĞ°Ğ½Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ½Ğ° 100% Ğ¾Ñ‚ lr
            total_iters=cfg.train.warmup_epochs
        )
        
        # Cosine scheduler: lr â†’ 1e-6 Ğ·Ğ° Ğ¾ÑÑ‚Ğ°Ğ²ÑˆĞ¸ĞµÑÑ ÑĞ¿Ğ¾Ñ…Ğ¸
        cosine_scheduler = CosineAnnealingLR(
            self.optimizer,
            T_max=cfg.train.num_epochs - cfg.train.warmup_epochs,
            eta_min=1e-6  # ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ LR
        )
        
        # ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼: ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° warmup, Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼ cosine
        self.scheduler = SequentialLR(
            self.optimizer,
            schedulers=[warmup_scheduler, cosine_scheduler],
            milestones=[cfg.train.warmup_epochs]
        )
        
        print(f"[train.py] Scheduler: Warmup({cfg.train.warmup_epochs}) + Cosine")
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Automatic Mixed Precision (AMP)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        #
        # AMP Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ FP16 (16-bit) Ğ²Ğ¼ĞµÑÑ‚Ğ¾ FP32 (32-bit) Ğ³Ğ´Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾:
        #   - Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ ~2x Ğ½Ğ° ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… GPU (Tensor Cores)
        #   - ĞœĞµĞ½ÑŒÑˆĞµ Ğ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
        #   - GradScaler Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ underflow Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        self.use_amp = cfg.use_amp
        if self.use_amp:
            self.scaler = torch.amp.GradScaler('cuda')
            print("[train.py] AMP (FP16) enabled")
        else:
            self.scaler = None
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Tracking Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        self.best_iou = 0.0        # Ğ›ÑƒÑ‡ÑˆĞ¸Ğ¹ IoU Ğ½Ğ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸
        self.start_epoch = 0       # ĞĞ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞ¿Ğ¾Ñ…Ğ° (Ğ´Ğ»Ñ Ğ²Ğ¾Ğ·Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ)
        self.current_epoch = 0     # Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ ÑĞ¿Ğ¾Ñ…Ğ°
    
    def save_checkpoint(
        self,
        epoch: int,
        is_best: bool = False,
        is_periodic: bool = False,
        reason: str = ""
    ) -> None:
        """
        Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.
        
        Ğ§ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚:
            - Ğ’ĞµÑĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
            - Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ° (Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ)
            - Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ scheduler
            - Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ AMP scaler
            - ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ (ÑĞ¿Ğ¾Ñ…Ğ°, Ğ»ÑƒÑ‡ÑˆĞ¸Ğ¹ IoU, ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³)
        
        Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ÑÑ:
            - latest.pth: Ğ²ÑĞµĞ³Ğ´Ğ° (Ğ´Ğ»Ñ Ğ²Ğ¾Ğ·Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ)
            - best.pth: ĞµÑĞ»Ğ¸ is_best=True
            - epoch_XXX.pth: ĞµÑĞ»Ğ¸ is_periodic=True
        
        Args:
            epoch: ĞĞ¾Ğ¼ĞµÑ€ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ ÑĞ¿Ğ¾Ñ…Ğ¸
            is_best: Ğ­Ñ‚Ğ¾ Ğ»ÑƒÑ‡ÑˆĞ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ?
            is_periodic: ĞŸĞµÑ€Ğ¸Ğ¾Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ?
            reason: ĞŸÑ€Ğ¸Ñ‡Ğ¸Ğ½Ğ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ (Ğ´Ğ»Ñ Ğ»Ğ¾Ğ³Ğ°)
        """
        
        # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¿Ğ°Ğ¿ĞºÑƒ ĞµÑĞ»Ğ¸ Ğ½Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚
        os.makedirs(self.cfg.paths.checkpoint_dir, exist_ok=True)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ state dict
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        state = {
            # Ğ’ĞµÑĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
            'model_state_dict': self.model.state_dict(),
            
            # Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ° (momentum, adaptive learning rates)
            'optimizer_state_dict': self.optimizer.state_dict(),
            
            # Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ scheduler (Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ LR, ÑÑ‡Ñ‘Ñ‚Ñ‡Ğ¸Ğº ÑĞ¿Ğ¾Ñ…)
            'scheduler_state_dict': self.scheduler.state_dict(),
            
            # Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ AMP scaler (Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ± Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²)
            'scaler_state_dict': self.scaler.state_dict() if self.scaler else None,
            
            # ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
            'epoch': epoch,
            'best_iou': self.best_iou,
            
            # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (Ğ´Ğ»Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹)
            'config': {
                'latent_dim': self.cfg.model.latent_dim,
                'num_frequencies': self.cfg.model.num_frequencies,
                'type': 'global'  # Ğ¢Ğ¸Ğ¿ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ñ‹
            }
        }
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        # Ğ’ÑĞµĞ³Ğ´Ğ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ latest (Ğ´Ğ»Ñ Ğ²Ğ¾Ğ·Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ)
        latest_path = os.path.join(self.cfg.paths.checkpoint_dir, 'latest.pth')
        torch.save(state, latest_path)
        
        if reason:
            print(f"[train.py] ğŸ’¾ Checkpoint saved: {reason}")
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ»ÑƒÑ‡ÑˆÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
        if is_best:
            best_path = os.path.join(self.cfg.paths.checkpoint_dir, 'best.pth')
            torch.save(state, best_path)
            print(f"[train.py] â­ Best model saved (IoU: {self.best_iou:.4f})")
        
        # ĞŸĞµÑ€Ğ¸Ğ¾Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ (ĞºĞ°Ğ¶Ğ´Ñ‹Ğµ N ÑĞ¿Ğ¾Ñ…)
        if is_periodic:
            periodic_path = os.path.join(
                self.cfg.paths.checkpoint_dir,
                f'epoch_{epoch + 1:03d}.pth'
            )
            torch.save(state, periodic_path)
            print(f"[train.py] ğŸ’¾ Periodic checkpoint: epoch_{epoch + 1:03d}.pth")
    
    def load_checkpoint(self, path: str) -> bool:
        """
        Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ° Ğ´Ğ»Ñ Ğ²Ğ¾Ğ·Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ.
        
        Args:
            path: ĞŸÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ° (.pth)
        
        Returns:
            True ĞµÑĞ»Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ°, False Ğ¸Ğ½Ğ°Ñ‡Ğµ
        """
        
        if not os.path.exists(path):
            print(f"[train.py] Checkpoint not found: {path}")
            return False
        
        print(f"[train.py] Loading checkpoint: {path}")
        
        try:
            # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ½Ğ° Ğ½ÑƒĞ¶Ğ½Ğ¾Ğµ ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ¾
            checkpoint = torch.load(
                path,
                map_location=self.device,
                weights_only=False  # Ğ Ğ°Ğ·Ñ€ĞµÑˆĞ°ĞµĞ¼ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºÑƒ Ğ¾Ğ±ÑŠĞµĞºÑ‚Ğ¾Ğ²
            )
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            
            # Scheduler (Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ½ĞµÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼ Ğ¿Ñ€Ğ¸ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸ num_epochs)
            if 'scheduler_state_dict' in checkpoint:
                try:
                    self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
                except Exception:
                    print("[train.py] Warning: scheduler state incompatible, resetting")
            
            # AMP scaler
            if self.scaler and checkpoint.get('scaler_state_dict'):
                self.scaler.load_state_dict(checkpoint['scaler_state_dict'])
            
            # ĞœĞµÑ‚Ğ°Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
            self.start_epoch = checkpoint.get('epoch', 0) + 1
            self.best_iou = checkpoint.get('best_iou', 0.0)
            
            print(f"[train.py] Resuming from epoch {self.start_epoch}")
            print(f"[train.py] Best IoU so far: {self.best_iou:.4f}")
            
            return True
            
        except Exception as e:
            print(f"[train.py] Error loading checkpoint: {e}")
            return False
    
    def train_epoch(
        self,
        loader: DataLoader,
        epoch: int
    ) -> tuple:
        """
        ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ğ´Ğ½Ğ¾Ğ¹ ÑĞ¿Ğ¾Ñ…Ğ¸.
        
        Args:
            loader: DataLoader Ñ Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸
            epoch: ĞĞ¾Ğ¼ĞµÑ€ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ ÑĞ¿Ğ¾Ñ…Ğ¸ (Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑĞ°)
        
        Returns:
            Tuple[avg_loss, avg_iou]: ÑÑ€ĞµĞ´Ğ½Ğ¸Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ·Ğ° ÑĞ¿Ğ¾Ñ…Ñƒ
        """
        global STOP_TRAINING
        
        # ĞŸĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
        # Ğ­Ñ‚Ğ¾ Ğ²Ğ»Ğ¸ÑĞµÑ‚ Ğ½Ğ° Dropout, BatchNorm Ğ¸ Ñ‚.Ğ´.
        self.model.train()
        
        # ĞĞºĞºÑƒĞ¼ÑƒĞ»ÑÑ‚Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
        total_loss = 0.0
        total_iou = 0.0
        n_batches = 0
        
        # ĞŸÑ€Ğ¾Ğ³Ñ€ĞµÑÑ-Ğ±Ğ°Ñ€
        pbar = tqdm(
            loader,
            desc=f"Epoch {epoch + 1}/{self.cfg.train.num_epochs}",
            ncols=100,
            leave=False
        )
        
        for batch in pbar:
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºÑƒ
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            if STOP_TRAINING:
                print("\n[train.py] Stopping training loop...")
                break
            
            # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ¿ÑƒÑÑ‚Ñ‹Ğµ Ğ±Ğ°Ñ‚Ñ‡Ğ¸ (ĞµÑĞ»Ğ¸ collate_fn Ğ²ĞµÑ€Ğ½ÑƒĞ» None)
            if batch is None:
                continue
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # ĞŸĞµÑ€ĞµĞ½Ğ¾Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° GPU
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            #
            # non_blocking=True: Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ° (Ğ½Ğµ Ğ±Ğ»Ğ¾ĞºĞ¸Ñ€ÑƒĞµÑ‚ CPU)
            # Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ CPU Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ñ‚ÑŒ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ Ğ±Ğ°Ñ‚Ñ‡ Ğ¿Ğ¾ĞºĞ° GPU Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            images = batch['image'].to(self.device, non_blocking=True)
            points = batch['points'].to(self.device, non_blocking=True)
            targets = batch['occupancies'].to(self.device, non_blocking=True)
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # ĞĞ±Ğ½ÑƒĞ»ĞµĞ½Ğ¸Ğµ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            #
            # set_to_none=True: Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ Ñ‡ĞµĞ¼ .zero_grad()
            # Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ñ‹ Ğ² None Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ Ğ½ÑƒĞ»ÑĞ¼Ğ¸
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            self.optimizer.zero_grad(set_to_none=True)
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Forward pass Ñ AMP (ĞµÑĞ»Ğ¸ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            #
            # autocast Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ²Ñ‹Ğ±Ğ¸Ñ€Ğ°ĞµÑ‚ FP16/FP32 Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸:
            #   - ĞœĞ°Ñ‚Ñ€Ğ¸Ñ‡Ğ½Ñ‹Ğµ ÑƒĞ¼Ğ½Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ: FP16 (Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾ Ğ½Ğ° Tensor Cores)
            #   - ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ, softmax: FP32 (Ğ´Ğ»Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸)
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            with torch.amp.autocast('cuda', enabled=self.use_amp):
                # Forward pass Ñ‡ĞµÑ€ĞµĞ· Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
                logits = self.model(images, points)
                
                # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ loss
                loss_dict = self.criterion(logits, targets)
                loss = loss_dict['total']
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Backward pass
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            if self.scaler:
                # Ğ¡ AMP: Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼ loss Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ underflow
                self.scaler.scale(loss).backward()
                
                # Gradient clipping
                # Unscale Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ñ‹ Ğ¿ĞµÑ€ĞµĞ´ clipping
                self.scaler.unscale_(self.optimizer)
                torch.nn.utils.clip_grad_norm_(
                    self.model.parameters(),
                    self.cfg.train.grad_clip
                )
                
                # Optimizer step Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¾Ğ¹ Ğ½Ğ° inf/nan
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                # Ğ‘ĞµĞ· AMP: ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¹ backward
                loss.backward()
                
                # Gradient clipping
                torch.nn.utils.clip_grad_norm_(
                    self.model.parameters(),
                    self.cfg.train.grad_clip
                )
                
                self.optimizer.step()
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # ĞĞ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ¸Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            total_loss += loss.item()
            total_iou += loss_dict['iou'].item()
            n_batches += 1
            
            # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ-Ğ±Ğ°Ñ€Ğ°
            pbar.set_postfix({
                'L': f"{loss.item():.3f}",
                'IoU': f"{loss_dict['iou'].item():.3f}"
            })
        
        # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ ÑÑ€ĞµĞ´Ğ½Ğ¸Ñ… Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹
        avg_loss = total_loss / max(n_batches, 1)
        avg_iou = total_iou / max(n_batches, 1)
        
        return avg_loss, avg_iou
    
    @torch.no_grad()  # ĞÑ‚ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²
    def validate(self, loader: DataLoader) -> tuple:
        """
        Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸.
        
        Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚ÑÑ Ğ‘Ğ•Ğ— Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²:
            - Ğ­ĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‚ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ GPU
            - Ğ£ÑĞºĞ¾Ñ€ÑĞµÑ‚ Ğ²Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ñ
            - ĞĞµ Ğ²Ğ»Ğ¸ÑĞµÑ‚ Ğ½Ğ° Ğ²ĞµÑĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        
        Args:
            loader: DataLoader Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸
        
        Returns:
            Tuple[avg_loss, avg_iou]: ÑÑ€ĞµĞ´Ğ½Ğ¸Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸
        """
        
        # ĞŸĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ² Ñ€ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ñ†ĞµĞ½ĞºĞ¸
        # ĞÑ‚ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Dropout, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ running stats Ğ´Ğ»Ñ BatchNorm
        self.model.eval()
        
        total_loss = 0.0
        total_iou = 0.0
        n_batches = 0
        
        for batch in tqdm(loader, desc="Validation", ncols=100, leave=False):
            if batch is None:
                continue
            
            images = batch['image'].to(self.device, non_blocking=True)
            points = batch['points'].to(self.device, non_blocking=True)
            targets = batch['occupancies'].to(self.device, non_blocking=True)
            
            with torch.amp.autocast('cuda', enabled=self.use_amp):
                logits = self.model(images, points)
                loss_dict = self.criterion(logits, targets)
            
            total_loss += loss_dict['total'].item()
            total_iou += loss_dict['iou'].item()
            n_batches += 1
        
        avg_loss = total_loss / max(n_batches, 1)
        avg_iou = total_iou / max(n_batches, 1)
        
        return avg_loss, avg_iou
    
    def train(
        self,
        train_loader: DataLoader,
        val_loader: DataLoader
    ) -> None:
        """
        ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ†Ğ¸ĞºĞ» Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ.
        
        Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚:
            1. Ğ¦Ğ¸ĞºĞ» Ğ¿Ğ¾ ÑĞ¿Ğ¾Ñ…Ğ°Ğ¼
            2. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° train_loader
            3. Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ½Ğ° val_loader
            4. Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ¾Ğ²
            5. ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ scheduler
        
        Args:
            train_loader: DataLoader Ğ´Ğ»Ñ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
            val_loader: DataLoader Ğ´Ğ»Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸
        """
        global STOP_TRAINING
        
        print("\n" + "=" * 60)
        print("TRAINING STARTED")
        print(f"Epochs: {self.start_epoch + 1} â†’ {self.cfg.train.num_epochs}")
        print(f"Batch size: {self.cfg.train.batch_size}")
        print(f"Learning rate: {self.cfg.train.learning_rate}")
        print("=" * 60)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Ğ¦Ğ¸ĞºĞ» Ğ¿Ğ¾ ÑĞ¿Ğ¾Ñ…Ğ°Ğ¼
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        for epoch in range(self.start_epoch, self.cfg.train.num_epochs):
            self.current_epoch = epoch
            epoch_start = datetime.now()
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºÑƒ Ğ¿ĞµÑ€ĞµĞ´ ÑĞ¿Ğ¾Ñ…Ğ¾Ğ¹
            if STOP_TRAINING:
                print(f"\n[train.py] Stopping before epoch {epoch + 1}")
                self.save_checkpoint(epoch - 1, reason="Stopped by user")
                break
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            train_loss, train_iou = self.train_epoch(train_loader, epoch)
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºÑƒ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
            if STOP_TRAINING:
                print(f"\n[train.py] Stopping after epoch {epoch + 1}")
                self.save_checkpoint(epoch, reason="Stopped by user")
                break
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            val_loss, val_iou = self.validate(val_loader)
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            epoch_time = (datetime.now() - epoch_start).total_seconds()
            current_lr = self.optimizer.param_groups[0]['lr']
            
            print(f"\nEpoch {epoch + 1}/{self.cfg.train.num_epochs}")
            print(f"  Train - Loss: {train_loss:.4f}, IoU: {train_iou:.4f}")
            print(f"  Val   - Loss: {val_loss:.4f}, IoU: {val_iou:.4f}")
            print(f"  LR: {current_lr:.2e} | Time: {epoch_time:.1f}s")
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ¾Ğ²
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ğ»ÑƒÑ‡ÑˆĞ°Ñ Ğ»Ğ¸ ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
            is_best = val_iou > self.best_iou
            if is_best:
                self.best_iou = val_iou
            
            # ĞŸĞµÑ€Ğ¸Ğ¾Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ
            is_periodic = (epoch + 1) % self.cfg.train.save_interval == 0
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ (latest Ğ²ÑĞµĞ³Ğ´Ğ°, best Ğ¸ periodic Ğ¿Ğ¾ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ñ)
            self.save_checkpoint(
                epoch,
                is_best=is_best,
                is_periodic=is_periodic
            )
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ scheduler
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            
            self.scheduler.step()
            
            # Flush stdout Ğ´Ğ»Ñ GUI (Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ»Ğ¾Ğ³Ğ¸ Ğ¿Ğ¾ÑĞ²Ğ»ÑĞ»Ğ¸ÑÑŒ ÑÑ€Ğ°Ğ·Ñƒ)
            sys.stdout.flush()
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        
        if not STOP_TRAINING:
            print("\n" + "=" * 60)
            print("TRAINING COMPLETE")
            print(f"Best Val IoU: {self.best_iou:.4f}")
            print(f"Checkpoints saved to: {self.cfg.paths.checkpoint_dir}")
            print("=" * 60)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN FUNCTION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """
    Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ.
    
    Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑĞµÑ‚:
        1. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºÑƒ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸
        2. Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºÑƒ random seed
        3. Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ² Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ñ‡Ğ¸ĞºĞ¾Ğ²
        4. Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Trainer
        5. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºÑƒ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ° (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
        6. Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
    """
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    cfg = get_config()
    
    print("=" * 60)
    print("OCCUPANCY NETWORK TRAINING")
    print(f"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    cfg.print_config()
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° random seed Ğ´Ğ»Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    torch.manual_seed(cfg.train.seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(cfg.train.seed)
        # Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ Ğ·Ğ° ÑÑ‡Ñ‘Ñ‚ Ğ°Ğ²Ñ‚Ğ¾Ğ¿Ğ¾Ğ´Ğ±Ğ¾Ñ€Ğ° Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼Ğ¾Ğ² cuDNN
        torch.backends.cudnn.benchmark = True
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ¾Ğ²
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    print("\n[1/3] Loading data...")
    
    # ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚
    full_dataset = Pix3DDataset(
        root_dir=cfg.paths.data_root,
        json_path=cfg.paths.json_path,
        num_points=cfg.train.num_points,
        is_train=True,
        category=cfg.train.category_filter
    )
    
    # Ğ Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ½Ğ° train/val
    n_total = len(full_dataset)
    n_val = int(n_total * cfg.train.val_split)
    n_train = n_total - n_val
    
    train_dataset, val_dataset = torch.utils.data.random_split(
        full_dataset,
        [n_train, n_val],
        generator=torch.Generator().manual_seed(cfg.train.seed)
    )
    
    print(f"[train.py] Train samples: {n_train}")
    print(f"[train.py] Val samples: {n_val}")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ DataLoader'Ğ¾Ğ²
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=cfg.train.batch_size,
        shuffle=True,                    # ĞŸĞµÑ€ĞµĞ¼ĞµÑˆĞ¸Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ°Ğ¶Ğ´ÑƒÑ ÑĞ¿Ğ¾Ñ…Ñƒ
        num_workers=cfg.train.num_workers,
        collate_fn=collate_fn,           # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ None
        drop_last=True,                  # ĞÑ‚Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼ Ğ½ĞµĞ¿Ğ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ±Ğ°Ñ‚Ñ‡
        pin_memory=cfg.train.pin_memory, # Ğ£ÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ğµ CPUâ†’GPU
        persistent_workers=True          # ĞĞµ Ğ¿ĞµÑ€ĞµÑĞ¾Ğ·Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ workers
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=cfg.train.batch_size,
        shuffle=False,
        num_workers=max(cfg.train.num_workers // 2, 1),
        collate_fn=collate_fn,
        pin_memory=cfg.train.pin_memory
    )
    
    print(f"[train.py] Train batches: {len(train_loader)}")
    print(f"[train.py] Val batches: {len(val_loader)}")
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Trainer
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    print("\n[2/3] Creating model...")
    trainer = Trainer(cfg)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ° (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    print("\n[3/3] Checking for existing checkpoint...")
    checkpoint_path = os.path.join(cfg.paths.checkpoint_dir, 'latest.pth')
    trainer.load_checkpoint(checkpoint_path)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    try:
        trainer.train(train_loader, val_loader)
    except Exception as e:
        print(f"\n[train.py] Error during training: {e}")
        import traceback
        traceback.print_exc()
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ‡ĞµĞºĞ¿Ğ¾Ğ¸Ğ½Ñ‚ Ğ¿Ñ€Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞµ
        trainer.save_checkpoint(
            trainer.current_epoch,
            reason=f"Error: {str(e)[:50]}"
        )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENTRY POINT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == '__main__':
    main()